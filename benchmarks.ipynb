{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ce230b-df68-40f5-8e19-e7c4934ff878",
   "metadata": {},
   "source": [
    "# ✅ Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8849dd8e-b940-429f-9579-1a495bac806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398f6e11-dbe0-4dba-89a5-dd12d9294bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklift.models import SoloModel\n",
    "from sklift.models import TwoModels\n",
    "from sklift.models import ClassTransformation\n",
    "from sklift.metrics import uplift_at_k\n",
    "from sklift.datasets import fetch_hillstrom\n",
    "\n",
    "from causalml.inference.meta.slearner import BaseSClassifier as CausalSoloModel\n",
    "from causalml.inference.meta.tlearner import BaseTClassifier as CausalTwoModels\n",
    "from causalml.inference.tree import UpliftTreeClassifier\n",
    "from causalml.inference.tree import UpliftRandomForestClassifier\n",
    "\n",
    "from upninja.pipelines import DataTransformers\n",
    "from upninja.pipelines import BasePipeline\n",
    "from upninja.utils.Score import upliftComparingHist, scoreUpliftAtK, scorePipelines\n",
    "from upninja.models import findBestParams, baseModelSelection\n",
    "from upninja.models import Spaces\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da2e47-5410-4c2f-8154-de1427cc987d",
   "metadata": {},
   "source": [
    "# ✅ Uplift на Kevin Hillstrom датасете"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3491d1-4a0f-488f-9559-f997e2d015b2",
   "metadata": {},
   "source": [
    "## ⭐ Загрузка и обработка Kevin Hillstrom датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc791bf-8e9e-4752-a746-1fbe0f03661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_hillstrom()\n",
    "X, y, t = data['data'], data['target'], data['treatment']\n",
    "# упростим целевую группу - сократим до была рассылка/не было рассылки\n",
    "t = t.map({'Womens E-Mail':1, 'Mens E-Mail':1, 'No E-Mail':0})\n",
    "\n",
    "X_train, X_test, y_train, y_test, t_train, t_test = train_test_split(X, \n",
    "                                                                     y, t, \n",
    "                                                                     test_size=0.3, \n",
    "                                                                     random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72f305-6513-4c1a-b1fe-1de5a051dfad",
   "metadata": {},
   "source": [
    "## ⭐ Выбор лучшей базовой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "900bcf1b-5bb6-4ab5-a3c0-7b89c4b7a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prepared = DataTransformers.HillstromTransformer().fit_transform(X_train)\n",
    "y_prepared = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10758f8e-579a-4061-b552-8def1b5feddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                     | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/usr/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:04<00:18,  4.64s/trial, best loss: -0.6274522168450039]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:13<00:00,  2.80s/trial, best loss: -0.6274522168450039]\n",
      "100%|███████████| 5/5 [00:22<00:00,  4.52s/trial, best loss: -0.553012915389317]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.71trial/s, best loss: -0.6031430900366076]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.98s/trial, best loss: -0.6159847855399736]\n",
      "100%|██████████| 5/5 [01:04<00:00, 12.96s/trial, best loss: -0.6120419386189359]\n"
     ]
    }
   ],
   "source": [
    "log_reg_best = findBestParams(LogisticRegression,\n",
    "                               X_prepared,\n",
    "                               y_prepared,\n",
    "                               Spaces.log_reg_hp_space\n",
    "                              )\n",
    "\n",
    "with open('saved_models/best_base/log_reg.pkl', 'wb') as f:\n",
    "    pickle.dump(log_reg_best, f)\n",
    "\n",
    "knn_best = findBestParams(KNeighborsClassifier,\n",
    "                               X_prepared,\n",
    "                               y_prepared,\n",
    "                               Spaces.knn_hp_space\n",
    "                              )\n",
    "\n",
    "with open('saved_models/best_base/knn.pkl', 'wb') as f:\n",
    "    pickle.dump(knn_best, f)\n",
    "\n",
    "dt_best = findBestParams(DecisionTreeClassifier,\n",
    "                               X_prepared,\n",
    "                               y_prepared,\n",
    "                               Spaces.dt_hp_space\n",
    "                              )\n",
    "\n",
    "with open('saved_models/best_base/dt.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_best, f)\n",
    "\n",
    "rf_best = findBestParams(RandomForestClassifier,\n",
    "                               X_prepared,\n",
    "                               y_prepared,\n",
    "                               Spaces.rf_hp_space\n",
    "                              )\n",
    "\n",
    "with open('saved_models/best_base/rf.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_best, f)\n",
    "\n",
    "cb_best = findBestParams(CatBoostClassifier,\n",
    "                               X_prepared,\n",
    "                               y_prepared,\n",
    "                               Spaces.cb_hp_space\n",
    "                              )\n",
    "\n",
    "with open('saved_models/best_base/cb.pkl', 'wb') as f:\n",
    "    pickle.dump(cb_best, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b2017a-e1d8-4b6b-a204-eb98b2b68e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_models/best_base/log_reg.pkl', 'rb') as f:\n",
    "    log_reg_best = pickle.load(f)\n",
    "\n",
    "with open('saved_models/best_base/knn.pkl', 'rb') as f:\n",
    "    knn_best = pickle.load(f)\n",
    "\n",
    "with open('saved_models/best_base/dt.pkl', 'rb') as f:\n",
    "    dt_best = pickle.load(f)\n",
    "\n",
    "with open('saved_models/best_base/rf.pkl', 'rb') as f:\n",
    "    rf_best = pickle.load(f)\n",
    "\n",
    "with open('saved_models/best_base/cb.pkl', 'rb') as f:\n",
    "    cb_best = pickle.load(f)\n",
    "\n",
    "log_reg_best['best_params']['max_iter'] = int(log_reg_best['best_params']['max_iter'])\n",
    "\n",
    "knn_best['best_params']['metric'] = knn_best['best_params']['metric'] if\\\n",
    "                                    knn_best['best_params']['metric'] in\\\n",
    "                                    {'pyfunc', 'l1', 'mahalanobis', 'minkowski',\n",
    "                                     'braycurtis', 'l2', 'chebyshev', 'correlation',\n",
    "                                     'seuclidean', 'sokalmichener', 'hamming', 'precomputed',\n",
    "                                     'euclidean', 'haversine', 'cosine', 'dice', 'russellrao',\n",
    "                                     'cityblock', 'sokalsneath', 'yule', 'infinity', 'sqeuclidean',\n",
    "                                     'manhattan', 'nan_euclidean', 'p', 'canberra',\n",
    "                                     'rogerstanimoto', 'jaccard'} else 'euclidean'\n",
    "knn_best['best_params']['weights'] = knn_best['best_params']['weights'] if\\\n",
    "                                     knn_best['best_params']['weights'] in\\\n",
    "                                     {'distance', 'uniform'} else 'distance'\n",
    "\n",
    "dt_best['best_params']['criterion'] = ['gini', 'entropy'][dt_best['best_params']['criterion']]\n",
    "dt_best['best_params']['max_depth'] = int(dt_best['best_params']['max_depth'])\n",
    "\n",
    "rf_best['best_params']['criterion'] = ['gini', 'entropy'][rf_best['best_params']['criterion']]\n",
    "rf_best['best_params']['max_depth'] = int(rf_best['best_params']['max_depth'])\n",
    "rf_best['best_params']['n_estimators'] = int(rf_best['best_params']['n_estimators'])\n",
    "\n",
    "cb_best['best_params']['verbose'] = False\n",
    "\n",
    "models = {\n",
    "    'LogisticRregressionSklearn': LogisticRegression(**log_reg_best['best_params']),\n",
    "    'KNearestSklearn': KNeighborsClassifier(**knn_best['best_params']),\n",
    "    'TreeClassifierSklearn': DecisionTreeClassifier(**dt_best['best_params']),\n",
    "    'RandomForestSklearn': RandomForestClassifier(**rf_best['best_params']),\n",
    "    'GradientBoostingCatBoost': CatBoostClassifier(**cb_best['best_params'])\n",
    "}\n",
    "\n",
    "res = baseModelSelection(models, X_prepared, y_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "436a250f-b85e-4e04-9a6f-67c8b84176e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNearestSklearn</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>1.523734</td>\n",
       "      <td>0.847366</td>\n",
       "      <td>0.553325</td>\n",
       "      <td>0.017513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TreeClassifierSklearn</td>\n",
       "      <td>0.046126</td>\n",
       "      <td>0.011746</td>\n",
       "      <td>0.853058</td>\n",
       "      <td>0.599789</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestSklearn</td>\n",
       "      <td>1.503427</td>\n",
       "      <td>0.115366</td>\n",
       "      <td>0.853058</td>\n",
       "      <td>0.615945</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRregressionSklearn</td>\n",
       "      <td>2.123291</td>\n",
       "      <td>0.034295</td>\n",
       "      <td>0.853058</td>\n",
       "      <td>0.627490</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingCatBoost</td>\n",
       "      <td>3.591814</td>\n",
       "      <td>0.025102</td>\n",
       "      <td>0.853036</td>\n",
       "      <td>0.613629</td>\n",
       "      <td>0.001819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model_name  fit_time  score_time  test_accuracy  \\\n",
       "1             KNearestSklearn  0.020528    1.523734       0.847366   \n",
       "2       TreeClassifierSklearn  0.046126    0.011746       0.853058   \n",
       "3         RandomForestSklearn  1.503427    0.115366       0.853058   \n",
       "0  LogisticRregressionSklearn  2.123291    0.034295       0.853058   \n",
       "4    GradientBoostingCatBoost  3.591814    0.025102       0.853036   \n",
       "\n",
       "   test_roc_auc   test_f1  \n",
       "1      0.553325  0.017513  \n",
       "2      0.599789  0.000000  \n",
       "3      0.615945  0.000000  \n",
       "0      0.627490  0.000000  \n",
       "4      0.613629  0.001819  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5670de2-3025-4e71-803f-acd74fb33f31",
   "metadata": {},
   "source": [
    "## ⭐ Протестируем Scikit-uplifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a614c7-90c2-4382-9466-83d4a5e097c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_models/best_base/cb.pkl', 'rb') as f:\n",
    "    cb_best = pickle.load(f)\n",
    "cb_best['best_params']['logging_level'] = 'Silent'\n",
    "\n",
    "s_learner_model = SoloModel(CatBoostClassifier(**cb_best['best_params']))\n",
    "\n",
    "s_learner_pipeline = BasePipeline.BasePipeline([\n",
    "    ('hilstrom-transformer', DataTransformers.HillstromTransformer()),\n",
    "    ('slearner', s_learner_model)\n",
    "])\n",
    "\n",
    "# независимые модели\n",
    "two_models_undepended_model = TwoModels(\n",
    "    CatBoostClassifier(**cb_best['best_params']),\n",
    "    CatBoostClassifier(**cb_best['best_params']),\n",
    "    method='vanilla'\n",
    ")\n",
    "\n",
    "two_models_undepended_pipeline = BasePipeline.BasePipeline([\n",
    "    ('hilstrom-transformer', DataTransformers.HillstromTransformer()),\n",
    "    ('two-models-undepended', two_models_undepended_model)\n",
    "])\n",
    "\n",
    "# зависимые модели\n",
    "two_models_depended_model = TwoModels(\n",
    "    CatBoostClassifier(**cb_best['best_params']),\n",
    "    CatBoostClassifier(**cb_best['best_params']),\n",
    "    method='ddr_control'\n",
    ")\n",
    "\n",
    "two_models_depended_pipeline = BasePipeline.BasePipeline([\n",
    "    ('hilstrom-transformer', DataTransformers.HillstromTransformer()),\n",
    "    ('two-models-depended', two_models_depended_model)\n",
    "])\n",
    "\n",
    "# Трансформация классов\n",
    "class_transform_model = ClassTransformation(\n",
    "    CatBoostClassifier(**cb_best['best_params'])\n",
    ")\n",
    "\n",
    "class_transform_pipeline = BasePipeline.BasePipeline([\n",
    "    ('hilstrom-transformer', DataTransformers.HillstromTransformer()),\n",
    "    ('class-transform', class_transform_model)\n",
    "])\n",
    "\n",
    "# соберем словарь для скоринга\n",
    "pipelines_unfited = {\n",
    "    'slearner': s_learner_pipeline,\n",
    "    'two-models-undepended': two_models_undepended_pipeline,\n",
    "    'two-models-depended': two_models_depended_pipeline,\n",
    "    'class-transform': class_transform_pipeline\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c4d1eee-4017-4f30-b81f-b3649fa92726",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = scorePipelines(pipelines_unfited,\n",
    "                     X_train, y_train,\n",
    "                     X_test, y_test,\n",
    "                     t_train, t_test\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f16a7875-6491-4723-b948-26253db8472d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>weighted_average_uplift_test</th>\n",
       "      <th>auqc_test</th>\n",
       "      <th>auuq_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class-transform</td>\n",
       "      <td>2.911708</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.065836</td>\n",
       "      <td>0.018426</td>\n",
       "      <td>0.010575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slearner</td>\n",
       "      <td>3.180722</td>\n",
       "      <td>0.197214</td>\n",
       "      <td>0.065959</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.017240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two-models-undepended</td>\n",
       "      <td>3.580388</td>\n",
       "      <td>0.185339</td>\n",
       "      <td>0.066015</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.001662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>two-models-depended</td>\n",
       "      <td>3.620152</td>\n",
       "      <td>0.188890</td>\n",
       "      <td>0.065764</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>0.006565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_name  fit_time  score_time  weighted_average_uplift_test  \\\n",
       "3        class-transform  2.911708    0.097244                      0.065836   \n",
       "0               slearner  3.180722    0.197214                      0.065959   \n",
       "1  two-models-undepended  3.580388    0.185339                      0.066015   \n",
       "2    two-models-depended  3.620152    0.188890                      0.065764   \n",
       "\n",
       "   auqc_test  auuq_test  \n",
       "3   0.018426   0.010575  \n",
       "0   0.030529   0.017240  \n",
       "1   0.002657   0.001662  \n",
       "2   0.010999   0.006565  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6b7ab5-8665-4816-85f3-b4551e53a6ea",
   "metadata": {},
   "source": [
    "## ⭐ Протестируем Causal-ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e218dc02-9f32-4743-9488-b89baf79b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_models/best_base/cb.pkl', 'rb') as f:\n",
    "    cb_best = pickle.load(f)\n",
    "cb_best['best_params']['logging_level'] = 'Silent'\n",
    "\n",
    "s_learner_model = CausalSoloModel(CatBoostClassifier(**cb_best['best_params']))\n",
    "\n",
    "s_learner_pipeline = BasePipeline.BasePipeline([\n",
    "    ('hilstrom-transformer', DataTransformers.HillstromTransformer()),\n",
    "    ('slearner', s_learner_model)\n",
    "])\n",
    "\n",
    "# независимые модели\n",
    "two_models_undepended_model = CausalTwoModels(\n",
    "    CatBoostClassifier(**cb_best['best_params']),\n",
    "    CatBoostClassifier(**cb_best['best_params'])\n",
    ")\n",
    "\n",
    "two_models_undepended_pipeline = BasePipeline.BasePipeline([\n",
    "    ('hilstrom-transformer', DataTransformers.HillstromTransformer()),\n",
    "    ('two-models-undepended', two_models_undepended_model)\n",
    "])\n",
    "\n",
    "# Uplift деревья\n",
    "uplift_tree = UpliftTreeClassifier(max_depth = 4,\n",
    "                                   min_samples_leaf = 200,\n",
    "                                   min_samples_treatment = 50,\n",
    "                                   n_reg = 100,\n",
    "                                   evaluationFunction='KL',\n",
    "                                   control_name='control')\n",
    "\n",
    "uplift_tree_pipeline = BasePipeline.BasePipeline([\n",
    "    ('hilstrom-transformer', DataTransformers.HillstromTransformer()),\n",
    "    ('uplift-tree', uplift_tree)\n",
    "])\n",
    "\n",
    "# Uplift лес\n",
    "# uplift_forest = UpliftRandomForestClassifier(n_estimators=5,\n",
    "#                                              max_depth=5,\n",
    "#                                              min_samples_leaf=200,\n",
    "#                                              min_samples_treatment=50,\n",
    "#                                              n_reg=100,\n",
    "#                                              evaluationFunction='KL',\n",
    "#                                              control_name='control')\n",
    "\n",
    "# uplift_forest_pipeline = BasePipeline.BasePipeline([\n",
    "#     ('hilstrom-transformer', DataTransformers.HillstromTransformer()),\n",
    "#     ('uplift-forest', uplift_forest)\n",
    "# ])\n",
    "\n",
    "# соберем словарь для скоринга\n",
    "pipelines_unfited = {\n",
    "    'slearner': s_learner_pipeline,\n",
    "    'two-models-undepended': two_models_undepended_pipeline,\n",
    "    'uplift-treeCausal': uplift_tree_pipeline\n",
    "    # 'uplift-forest-treeCausal': uplift_forest_pipeline\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ffc950-877d-4bfc-bf77-a7b0532148c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = scorePipelines(pipelines_unfited,\n",
    "                     X_train, y_train,\n",
    "                     X_test, y_test,\n",
    "                     t_train, t_test\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9fa8d8c-ff04-4507-929d-b4074c7b32ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>weighted_average_uplift_test</th>\n",
       "      <th>auqc_test</th>\n",
       "      <th>auuq_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uplift-treeCausal</td>\n",
       "      <td>0.283952</td>\n",
       "      <td>0.045854</td>\n",
       "      <td>0.066327</td>\n",
       "      <td>0.021342</td>\n",
       "      <td>0.012665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slearner</td>\n",
       "      <td>3.482134</td>\n",
       "      <td>0.212114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.265490</td>\n",
       "      <td>-0.153391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two-models-undepended</td>\n",
       "      <td>4.121654</td>\n",
       "      <td>0.198643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.265490</td>\n",
       "      <td>-0.153391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_name  fit_time  score_time  weighted_average_uplift_test  \\\n",
       "2      uplift-treeCausal  0.283952    0.045854                      0.066327   \n",
       "0               slearner  3.482134    0.212114                           NaN   \n",
       "1  two-models-undepended  4.121654    0.198643                           NaN   \n",
       "\n",
       "   auqc_test  auuq_test  \n",
       "2   0.021342   0.012665  \n",
       "0  -0.265490  -0.153391  \n",
       "1  -0.265490  -0.153391  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0524930b-b328-42d3-a41f-431bbcddf171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  1.136803388595581\n",
      "Score time:  1.8871386051177979\n",
      "weighted_average_uplift_test nan\n",
      "auqc_test -0.2654903525647612\n",
      "auuq_test -0.15339137562549263\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from sklift.metrics import weighted_average_uplift\n",
    "from sklift.metrics import qini_auc_score\n",
    "from sklift.metrics import uplift_auc_score\n",
    "\n",
    "\n",
    "X_train_RF = DataTransformers.HillstromTransformer().fit_transform(X_train)\n",
    "X_test_RF = DataTransformers.HillstromTransformer().fit_transform(X_test)\n",
    "\n",
    "t_train_RF = t_train.map({0: 'no-control', 1: 'control'})\n",
    "t_test_RF = t_test.map({0: 'no-control', 1: 'control'})\n",
    "\n",
    "uplift_forest = UpliftRandomForestClassifier(n_estimators=5,\n",
    "                                             max_depth=5,\n",
    "                                             min_samples_leaf=200,\n",
    "                                             min_samples_treatment=50,\n",
    "                                             n_reg=100,\n",
    "                                             evaluationFunction='KL',\n",
    "                                             control_name='control')\n",
    "\n",
    "start_fit_time = time.time()\n",
    "uplift_forest.fit(X_train_RF.values, t_train_RF.values, y_train.values)\n",
    "print('Fit time: ', time.time() - start_fit_time)\n",
    "\n",
    "start_score_time = time.time()\n",
    "scores = uplift_forest.predict(X_test_RF.values)\n",
    "print('Score time: ', time.time() - start_fit_time)\n",
    "\n",
    "t_test_RF = t_test.copy()\n",
    "\n",
    "print('weighted_average_uplift_test', weighted_average_uplift(y_test.values, scores, t_test_RF.values, bins=10))\n",
    "print('auqc_test', qini_auc_score(y_test.values, scores, t_test_RF.values))\n",
    "print('auuq_test', uplift_auc_score(y_test.values, scores, t_test_RF.values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
